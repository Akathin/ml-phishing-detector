if __name__ == '__main__':
    import pandas as pd
    import numpy as np
    import shap
    import joblib
    import matplotlib.pyplot as plt
    import seaborn as sns
    from tqdm import tqdm
    from joblib import Parallel, delayed
    import multiprocessing
    from sklearn.pipeline import Pipeline
    from sklearn.impute import SimpleImputer
    from sklearn.preprocessing import StandardScaler
    from sklearn.ensemble import RandomForestClassifier
    from xgboost import XGBClassifier
    from sklearn.linear_model import LogisticRegression

    # ----------------------------
    # 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
    # ----------------------------
    df = pd.read_csv("2025_URL_DATASET.csv")  #ë¡œì»¬ ì‚¬ìš© ì‹œ ê²½ë¡œ ìˆ˜ì •
    X = df.drop(columns=["url", "label"], errors="ignore")
    y = df["label"]
    feature_names = X.columns.tolist()

    preprocessor = Pipeline([
        ("imputer", SimpleImputer(strategy="mean")),
        ("scaler", StandardScaler())
    ])
    X_scaled = np.array(preprocessor.fit_transform(X))

    # ----------------------------
    # 2. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    # ----------------------------
    voting_model = joblib.load("vc_old_model.pkl")    #ë¡œì»¬ ì‚¬ìš© ì‹œ ê²½ë¡œ ìˆ˜ì •
    model_weights = voting_model.weights or [1] * len(voting_model.estimators)
    named_models = dict(voting_model.named_estimators_)

    # ----------------------------
    # 3. ëª¨ë¸ ë¶„ë¦¬ (ë³‘ë ¬ vs ì§ë ¬)                   #ë³‘ë ¬: TreeExplainer, LinearExplainer /   ì§ë ¬: KernelExplainer
    # ----------------------------
    parallel_models = {}
    serial_models = {}

    for name, model in named_models.items():
        if isinstance(model, (RandomForestClassifier, XGBClassifier, LogisticRegression)):
            parallel_models[name] = model
        else:
            serial_models[name] = model

    background = np.array(shap.sample(X_scaled, 50, random_state=42))  # memmap ë°©ì§€

    # ----------------------------
    # 4. SHAP ê³„ì‚° í•¨ìˆ˜ (ë³‘ë ¬ ëŒ€ìƒ)
    # ----------------------------
    def compute_shap_for_model(model_name, model, position):
        print(f"ğŸ” {model_name} SHAP ê³„ì‚° ì‹œì‘")

        if isinstance(model, (RandomForestClassifier, XGBClassifier)):
            explainer = shap.TreeExplainer(model)
        elif isinstance(model, LogisticRegression):
            explainer = shap.LinearExplainer(model, background)
        else:
            raise ValueError(f"{model_name}: ë³‘ë ¬ ëŒ€ìƒ ì•„ë‹˜")

        shap_values = []
        for x in tqdm(X_scaled, desc=f"{model_name} SHAP", position=position, leave=True, dynamic_ncols=True):
            x_reshaped = x.reshape(1, -1)
            shap_val = explainer(x_reshaped)
            values = shap_val[1].values if isinstance(shap_val, list) else shap_val.values
            shap_values.append(np.abs(values))

        shap_array = np.vstack(shap_values)
        feature_importance = np.mean(shap_array, axis=0).flatten()

        min_len = min(len(feature_names), len(feature_importance))
        df = pd.DataFrame({
            "Feature": feature_names[:min_len],
            f"{model_name}_SHAP_ì¤‘ìš”ë„": feature_importance[:min_len]
        })
        return model_name, df

    # ----------------------------
    # 5. ë³‘ë ¬ SHAP ì‹¤í–‰
    # ----------------------------
    n_jobs = int(multiprocessing.cpu_count() * 0.7)     #ë³¸ì¸ ì»´í“¨í„° ì‚¬ì–‘ì´ ê´œì°®ë‹¤ë©´ n_jobs=-1 ì„¤ì •(cpu 100%)
    print(f"âš™ï¸ ë³‘ë ¬ ì²˜ë¦¬ì— ì‚¬ìš©í•  ì½”ì–´ ìˆ˜: {n_jobs} / {multiprocessing.cpu_count()}")

    results = Parallel(n_jobs=n_jobs)(
        delayed(compute_shap_for_model)(name, model, position=i+1)
        for i, (name, model) in enumerate(parallel_models.items())
    )

    # ----------------------------
    # 6. ì§ë ¬ SHAP ì‹¤í–‰ (KernelExplainer)
    # ----------------------------
    for i, (model_name, model) in enumerate(serial_models.items()):
        print(f"ğŸ” {model_name} (KernelExplainer) SHAP ì§ë ¬ ê³„ì‚° ì‹œì‘...")

        explainer = shap.KernelExplainer(model.predict_proba, background)
        shap_values = []

        disable_tqdm = X_scaled.shape[0] == 1
        for x in tqdm(X_scaled, desc=f"{model_name} SHAP", position=10+i, leave=True, dynamic_ncols=True, disable=disable_tqdm):
            x_reshaped = x.reshape(1, -1)
            shap_val = explainer(x_reshaped)
            values = shap_val[1].values if isinstance(shap_val, list) else shap_val.values
            shap_values.append(np.abs(values))

        shap_array = np.vstack(shap_values)
        feature_importance = np.mean(shap_array, axis=0).flatten()

        min_len = min(len(feature_names), len(feature_importance))
        df = pd.DataFrame({
            "Feature": feature_names[:min_len],
            f"{model_name}_SHAP_ì¤‘ìš”ë„": feature_importance[:min_len]
        })
        results.append((model_name, df))

    # ----------------------------
    # 7. Voting ê°€ì¤‘ì¹˜ ë°˜ì˜
    # ----------------------------
    print("âœ… ëª¨ë¸ ê°€ì¤‘ì¹˜ ë°˜ì˜ ì¤‘...")

    model_importance = {name: df for name, df in results}
    final_df = list(model_importance.values())[0]
    for df in list(model_importance.values())[1:]:
        final_df = final_df.merge(df, on="Feature", how="outer")
    final_df.fillna(0, inplace=True)

    importance_cols = [col for col in final_df.columns if col.endswith("_SHAP_ì¤‘ìš”ë„")]
    weights_array = np.array(model_weights)
    final_df["SHAP_ê°€ì¤‘_ì¤‘ìš”ë„"] = final_df[importance_cols].values.dot(weights_array) / weights_array.sum()
    final_df = final_df.sort_values(by="SHAP_ê°€ì¤‘_ì¤‘ìš”ë„", ascending=False)

    # ----------------------------
    # 8. ì €ì¥ ë° ì‹œê°í™”
    # ----------------------------
    final_df.to_csv("shap_weighted_feature_importance.csv", index=False)

    plt.figure(figsize=(12, 8))
    sns.barplot(data=final_df.head(20), x="SHAP_ê°€ì¤‘_ì¤‘ìš”ë„", y="Feature", palette="viridis")
    plt.title("Top 20 SHAP Features importance")
    plt.tight_layout()
    plt.savefig("shap_weighted_feature_importance.png")
    plt.close()

    print("âœ… SHAP ë¶„ì„ ì™„ë£Œ!")
    print(" - shap_weighted_feature_importance.csv")
    print(" - shap_weighted_feature_importance.png")
